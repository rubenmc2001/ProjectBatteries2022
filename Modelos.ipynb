{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANEXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las librerias utilizadas han sido las siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree\n",
    "\n",
    "# Preprocesado\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Optimización de parámetros\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos que utilizaremos para realizar el proyecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel('dataset_escalado.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las variables cualitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID_PDA','SN_PDA','FECHA_FAB','FECHA_TEST','SN_BAT'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función me permite eliminar de la base de datos los valores que son NaN y los Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variable X junto con la variable objetivo y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ESTADO_BAT'], axis=1).values\n",
    "y = df['ESTADO_BAT'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un histograma para observar la distribución de las clases presenten en la variable objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot('ESTADO_BAT',data=df,kind=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División de los datos en train y en test y aplicamos el algoritmo SMOTE a los datos de train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        df.drop(columns = 'ESTADO_BAT'),\n",
    "                                        df['ESTADO_BAT'],\n",
    "                                        random_state = 123,\n",
    "                                        stratify = df['ESTADO_BAT'],\n",
    "                                        train_size=0.7)\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=2, random_state=100)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos una función para optimar los parámetros óptimos de los diferentes modelos probados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clfGrid(X, y, clasificadores, n_clas):\n",
    "    res = {}\n",
    "    for clf_cnt, clf in enumerate(clasificadores):\n",
    "        clf.fit(X, y)     \n",
    "        res[n_clas[clf_cnt]] = {}\n",
    "        res[n_clas[clf_cnt]][\"F1\"] = clf.best_score_\n",
    "        res[n_clas[clf_cnt]][\"Mejor clasificador\"] = clf.best_estimator_\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los siguientes clasificadores junto con la métrica f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score , average='weighted')\n",
    "\n",
    "clasificadores = [GridSearchCV(estimator=LogisticRegression(), \n",
    "                               param_grid = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                                             'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'), \n",
    "                                             'max_iter' : [100, 200, 300]}, scoring=f1),\n",
    "                  \n",
    "                  GridSearchCV(estimator=AdaBoostClassifier(), \n",
    "                               param_grid = {'n_estimators':[50,100,200,500]}, \n",
    "                               scoring=f1),\n",
    "                  \n",
    "                  GridSearchCV(estimator=LinearSVC(), \n",
    "                               param_grid = {'C':[0.1,1,1.5]}, scoring=f1),\n",
    "                  \n",
    "                  GridSearchCV(estimator=KNeighborsClassifier(), \n",
    "                               param_grid = {'n_neighbors':[1,2,3,4,5,6], \n",
    "                                             'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                             'p':[1,2]}, scoring=f1),\n",
    "                  \n",
    "                  GridSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                               param_grid = {'criterion':['gini','entropy'],\n",
    "                                             'splitter':['random','best'],\n",
    "                                             'min_samples_split':[2,4,6], \n",
    "                                             'max_depth': [2, 5, 10, 15, 20], \n",
    "                                             'min_samples_leaf': [5, 4, 3, 2, 1]}, \n",
    "                               scoring=f1),\n",
    "                  \n",
    "                 GridSearchCV(estimator = MLPClassifier(random_state = 1), \n",
    "                              param_grid={'activation': ('identity', 'logistic', 'tanh', 'relu'), \n",
    "                                          'solver': ('lbfgs', 'sgd', 'adam'), 'max_iter': [2, 5, 10]}, \n",
    "                              scoring=f1),\n",
    "                  \n",
    "                 GridSearchCV(estimator = SVC(random_state = 1), \n",
    "                              param_grid = dict(C = [1,2,4], gamma = ['scale', 'auto'], \n",
    "                                                kernel = ['poly', 'rbf', 'sigmoid']), \n",
    "                              scoring=f1)]\n",
    "\n",
    "n_clas = ['Regressión logística', 'AdaBoost', 'SVC Lineal','Vecinos','Arboles', 'Perceptrón Multicapa', 'SVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfGrid(X_train,y_train, clasificadores, n_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenidos los parámetros óptimos de los diferentes clasificadores, pasaremos a aplicar cada modelo con sus parámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que nos proporcionará la métrica brier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de Árboles de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = DecisionTreeClassifier(max_depth = 10, splitter=\"random\",random_state=10)\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El Brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 de predict da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 cross-val da(Decision Tree): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la estructura del árbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(21, 10))\n",
    "\n",
    "print(f\"Profundidad del árbol: {modelo.get_depth()}\")\n",
    "print(f\"Número de nodos terminales: {modelo.get_n_leaves()}\")\n",
    "\n",
    "plot = plot_tree(\n",
    "            decision_tree = modelo,\n",
    "            feature_names = list(df.drop(['ESTADO_BAT'], axis=1)),\n",
    "            filled        = True,\n",
    "            impurity      = False,\n",
    "            fontsize      = 7,\n",
    "            ax            = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos la estructura del árbol que nos proporciona dicho modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"árbol_clasificación.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente obtenemos la importacia que han tenido las variables en el modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "importancia_predictores = pd.DataFrame(\n",
    "                            {'predictor': df.drop(columns = \"ESTADO_BAT\").columns,\n",
    "                             'importancia': modelo.feature_importances_}\n",
    "                            )\n",
    "importancia_predictores.sort_values('importancia', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo =  LogisticRegression(C=1, solver='liblinear')\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (Regresión Logística): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de K-Vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo =  KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (KNN): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de Máquinas de Vectores Soporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo =  SVC(C=4, gamma='auto', random_state=1,probability=True)\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (SVC): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos Stacking con los diferentes clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('mlp',MLPClassifier(random_state=1, max_iter=1000)),('LinearSVC', LinearSVC(C=0.1, max_iter=10000))]\n",
    "modelo=StackingClassifier(estimators=estimators,final_estimator=KNeighborsClassifier(n_neighbors=1, p=1))\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (Stacking): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos Bagging con los diferentes clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=1, p=1),n_estimators=200)\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (Bagging): {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos Boosting con los diferentes clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=AdaBoostClassifier(base_estimator=LogisticRegression(C=0.1, max_iter=100, penalty='l2',\n",
    "                            random_state=10, solver='lbfgs'),n_estimators=200, algorithm='SAMME')\n",
    "f1 = cross_val_score(modelo, X_train,y_train,cv=5 ,scoring = 'f1_weighted').mean()\n",
    "fit = modelo.fit(X_train,y_train)\n",
    "pred = modelo.predict(X_test)\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "bien = []\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        bien.append([1,0,0,0])\n",
    "    elif i == 25:\n",
    "        bien.append([0,1,0,0])\n",
    "    elif i == 50:\n",
    "        bien.append([0,0,1,0])\n",
    "    elif i == 75:\n",
    "        bien.append([0,0,0,1])\n",
    "bien = np.array(bien)\n",
    "print('Los valores de las métricas para dicho modelo son los siguientes: ')\n",
    "print(f'El brier Score da:',brier_multi(probs,bien))\n",
    "print(f'El f1 predicho da:',f1_score(y_test,pred, average='weighted'))\n",
    "print(f'F1 (Boosting): {f1:.5f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PL3_S1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
